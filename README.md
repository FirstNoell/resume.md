Leoncio U. Coronado Jr. 
+63 9566772237 coronadonoell@gmail.com 
Git Hub URL: https://github.com/FirstNoell/my-portfolio-amazon.git 
  
Professional Summary 
Detail-oriented Data Science Intern with extensive experience in Python, Selenium, and Scrapy, specializing in automating data collection and deriving actionable insights from large datasets. Known for a strong passion for workflow optimization and a keen ability to extract valuable information from dynamic web sources, including e-commerce platforms with JavaScript-heavy frameworks. Enthusiastic about contributing to innovative solutions and continuously expanding technical expertise. 
Skills 
	• 	Programming Languages: Python, SQL, HTML, CSS 
•	Data Science Tools: Pandas, NumPy, Matplotlib 
•	Web Scraping Tools: Selenium, Scrapy, BeautifulSoup 
•	Databases: SQLite, MongoDB 
  
Education 
Technological Institute of the Philippines 
Electrical Engineering (Undergraduate), 1988 – 1991 
Data Science Short Course 
Udemy 
Date of Completion: September 21, 2024 
  
Certificates of Completion 
  
  
Work Experience 
Freelance Data Science Intern 
June 2023 – Present 
•	Assisted with data collection, cleaning, and analysis for various client projects, focusing on web scraping and data automation. 
•	Developed automated web scraping scripts using Python and Selenium to gather extensive datasets from websites with heavy JavaScript frameworks, including e-commerce sites like Amazon. 
•	Analyzed and visualized data trends, providing actionable insights for stakeholders. 
•	Collaborated with team members to implement machine learning models to predict key metrics. 
  
Projects 
E-commerce Product Scraping Project Using Scrapy and Splash Amazon Product Scraper 
April 2025 
•	Built a Scrapy-Selenium web scraper to extract product details, reviews, prices, and availability from Amazon product pages. 
•	Handled pagination and dynamic content loading to ensure data extraction accuracy. 
•	Used Python and Scrapy's Crawl Spider for targeted scraping. 
eBay Price Tracker 
•	Developed a Scrapy spider to scrape product listings and track price trends on eBay. 
•	Focused on gathering product data such as title, price, and seller details for market analysis. 
Implemented data storage in SQLite for future analysis. 
 
Gas Prices Scraping Project 
August 2024 
•	Created a Scrapy spider to collect gas prices for various states from the AAA Gas Prices website, including current, yesterday's, and year-ago averages. 
•	Employed Selenium to interact with dynamic web elements, ensuring accurate data extraction. 
•	Stored scraped data in a SQLite database for efficient querying and analysis. 
Tools:  Selenium, SQLite Movie Transcripts Scraping Project 
September 2024 
•	Developed a Scrapy spider to extract movie transcripts from Subslikescript.com. 
•	Parsed and structured data to retrieve titles, plots, and URLs, saving results in a well-organized SQLite database. 
•	Automated the scraping process to run on a schedule, regularly updating the database with new entries. 
Tools: Scrapy, SQLite 
 
October 2024 
•	Designed and implemented a web scraping solution to extract product data from Amazon, utilizing Scrapy and Splash to handle JavaScript-rendered content. 
•	Configured Splash to render JavaScript elements and integrated it with Scrapy to efficiently retrieve product titles, prices, ratings, links, and other key details from Amazon’s dynamically loaded pages. 
•	Developed a custom pipeline to clean and store the scraped data in a MongoDB database, enabling advanced querying and facilitating competitive market analysis. 
Tools: Scrapy, Splash, MongoDB. Compiled and stored the scraped data in a MongoDB database for advanced querying and analysis, facilitating competitive market research. Tools: Selenium, BeautifulSoup, Scrapy, MongoDB 
Reddit Data Analysis Project Using Scrapy and Splash 
November,2024 
•	Developed a Scrapy spider integrated with Splash to collect data from Reddit posts, including titles, user comments, upvotes, and timestamps, overcoming JavaScript-rendered content on subreddit pages. 
•	Configured Splash to render JavaScript-heavy content, enabling effective data extraction from dynamically loaded elements on Reddit pages. 
•	Utilized custom pipelines to preprocess and store the scraped data in a SQLite database for easy querying and analysis. 
•	Applied natural language processing (NLP) techniques to analyze comment sentiment and visualize trends, providing actionable insights into user sentiment and popular topics on Reddit. 
Tools: Scrapy, Splash, SQLite, Pandas, NLTK, Matplotlib 
  
Languages 
•	English 
•	Filipino
  
